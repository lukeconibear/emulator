{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "from tpot.export_utils import set_param_recursive\n",
    "import xarray as xr\n",
    "from SALib.sample import saltelli\n",
    "from SALib.analyze import sobol\n",
    "import joblib\n",
    "import re\n",
    "import os\n",
    "import dask\n",
    "import dask.bag as db\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.feature import ShapelyFeature\n",
    "from cartopy.io.shapereader import Reader\n",
    "params = {\n",
    "    'text.latex.preamble': ['\\\\usepackage{gensymb}'],\n",
    "    'axes.grid': False,\n",
    "    'savefig.dpi': 700,\n",
    "    'font.size': 12,\n",
    "    'text.usetex': False,\n",
    "    'figure.figsize': [5, 5],\n",
    "    'font.family': 'serif',\n",
    "}\n",
    "matplotlib.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_jobqueue import SGECluster\n",
    "from dask.distributed import Client\n",
    "\n",
    "cluster = SGECluster(\n",
    "    walltime='12:00:00', \n",
    "    memory='2 G',\n",
    "    resource_spec='h_vmem=2G',\n",
    "    scheduler_options={\n",
    "        'dashboard_address': ':5757',\n",
    "    },\n",
    "    project='admiralty'\n",
    ")\n",
    "\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.scale(jobs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()\n",
    "cluster.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = 'PM2_5_DRY'\n",
    "path = '/nobackup/earlacoa/machinelearning/data/'\n",
    "\n",
    "with open(path + 'dict_train.pickle', 'rb') as ds:\n",
    "    dict_train = pickle.load(ds)\n",
    "    \n",
    "df_train = pd.concat(dict_train, ignore_index=True)\n",
    "gridcells = df_train[['lat', 'lon']].drop_duplicates().values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### create control using emulators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = [\n",
    "    'PM2_5_DRY',\n",
    "    'o3',\n",
    "    'AOD550_sfc',\n",
    "    'asoaX_2p5',\n",
    "    'bc_2p5',\n",
    "    'bsoaX_2p5',\n",
    "    'nh4_2p5',\n",
    "    'no3_2p5',\n",
    "    'oc_2p5',\n",
    "    'oin_2p5',\n",
    "    'so4_2p5'\n",
    "]\n",
    "\n",
    "fraction_res = 1.0\n",
    "fraction_ind = 1.0\n",
    "fraction_tra = 1.0\n",
    "fraction_agr = 1.0\n",
    "fraction_ene = 1.0\n",
    "\n",
    "custom_inputs = np.array([\n",
    "    fraction_res,\n",
    "    fraction_ind,\n",
    "    fraction_tra,\n",
    "    fraction_agr,\n",
    "    fraction_ene\n",
    "]).reshape(1, -1)\n",
    "\n",
    "empty_values = np.empty((580, 1440))\n",
    "empty_values[:] = np.nan\n",
    "\n",
    "for output in outputs:\n",
    "    emulator_files = glob.glob(path + output + '/emulator_' + output + '_*.joblib')\n",
    "    \n",
    "    ds_custom_output = xr.DataArray(\n",
    "        empty_values, \n",
    "        dims=('lat', 'lon'), \n",
    "        coords={'lat': np.arange(-60, 85, 0.25), 'lon': np.arange(-180, 180, 0.25)}\n",
    "    )\n",
    "    \n",
    "    for emulator_file in emulator_files:\n",
    "        lat, lon = [float(item) for item in re.findall(r'\\d+\\.\\d+', emulator_file)]\n",
    "        emulator = joblib.load(emulator_file)\n",
    "        \n",
    "        try:\n",
    "            custom_output = emulator.predict(custom_inputs)\n",
    "            ds_custom_output = xr.where(\n",
    "                (ds_custom_output.coords['lat'] == lat) & (ds_custom_output.coords['lon'] == lon),\n",
    "                custom_output,\n",
    "                ds_custom_output\n",
    "            )\n",
    "        except:\n",
    "            RuntimeError\n",
    "    \n",
    "    ds_custom_output.name = output\n",
    "    ds_custom_output.to_netcdf(\n",
    "        path + 'summary/ds_ctl_' + output + '.nc'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### create individual 10% emulators while holding other inputs at 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = 'PM2_5_DRY'\n",
    "#output = 'o3'\n",
    "\n",
    "emulator_files = glob.glob(path + output + '/emulator_' + output + '_*.joblib')\n",
    "\n",
    "empty_values = np.empty((580, 1440))\n",
    "empty_values[:] = np.nan\n",
    "\n",
    "matrix1 = np.array(np.meshgrid(np.linspace(0, 1.5, 16), 1, 1, 1, 1)).T.reshape(-1, 5)\n",
    "matrix2 = np.array(np.meshgrid(1, np.linspace(0, 1.5, 16), 1, 1, 1)).T.reshape(-1, 5)\n",
    "matrix3 = np.array(np.meshgrid(1, 1, np.linspace(0, 1.5, 16), 1, 1)).T.reshape(-1, 5)\n",
    "matrix4 = np.array(np.meshgrid(1, 1, 1, np.linspace(0, 1.5, 16), 1)).T.reshape(-1, 5)\n",
    "matrix5 = np.array(np.meshgrid(1, 1, 1, 1, np.linspace(0, 1.5, 16))).T.reshape(-1, 5)\n",
    "matrix_stacked = np.vstack((matrix1, matrix2, matrix3, matrix4, matrix5))\n",
    "\n",
    "for matrix in matrix_stacked:\n",
    "    custom_inputs = matrix.reshape(1, -1)\n",
    "    filename = 'RES' + str(np.round(custom_inputs[0][0], decimals=1)) \\\n",
    "                + '_IND' + str(np.round(custom_inputs[0][1], decimals=1)) \\\n",
    "                + '_TRA' + str(np.round(custom_inputs[0][2], decimals=1)) \\\n",
    "                + '_AGR' + str(np.round(custom_inputs[0][3], decimals=1)) \\\n",
    "                + '_ENE' + str(np.round(custom_inputs[0][4], decimals=1))\n",
    "\n",
    "    ds_custom_output = xr.DataArray(\n",
    "        empty_values, \n",
    "        dims=('lat', 'lon'), \n",
    "        coords={'lat': np.arange(-60, 85, 0.25), 'lon': np.arange(-180, 180, 0.25)}\n",
    "    )\n",
    "\n",
    "    for emulator_file in emulator_files:\n",
    "        lat, lon = [float(item) for item in re.findall(r'\\d+\\.\\d+', emulator_file)]\n",
    "        emulator = joblib.load(emulator_file)\n",
    "        custom_output = emulator.predict(custom_inputs)\n",
    "        ds_custom_output = xr.where(\n",
    "            (ds_custom_output.coords['lat'] == lat) & (ds_custom_output.coords['lon'] == lon),\n",
    "            custom_output,\n",
    "            ds_custom_output\n",
    "        )\n",
    "    \n",
    "    ds_custom_output.name = output\n",
    "    \n",
    "    ds_custom_output.to_netcdf(\n",
    "        path + '/summary/ds_' + filename + '_' + output + '.nc'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### create 10% emulators - pangeo\n",
    "parallelise over the custom inputs (as these are independent, while the dataset for gridcells are dependent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_stacked = np.array(np.meshgrid(\n",
    "    np.linspace(0, 1.5, 16), \n",
    "    np.linspace(0, 1.5, 16),\n",
    "    np.linspace(0, 1.5, 16),\n",
    "    np.linspace(0, 1.5, 16),\n",
    "    np.linspace(0, 1.5, 16)\n",
    ")).T.reshape(-1, 5)\n",
    "\n",
    "custom_inputs = [item.reshape(1, -1) for item in matrix_stacked]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicates of ones already completed\n",
    "custom_inputs_completed_filenames = glob.glob(path + 'summary/ds*')\n",
    "custom_inputs_completed_list = []\n",
    "for custom_inputs_completed_filename in custom_inputs_completed_filenames:\n",
    "    custom_inputs_completed_list.append(\n",
    "        [float(item) for item in re.findall(r'\\d+\\.\\d+', custom_inputs_completed_filename)]\n",
    "    )\n",
    "    \n",
    "custom_inputs_list = []\n",
    "for custom_input in custom_inputs:\n",
    "    custom_inputs_list.append(\n",
    "        [float(item) for item in re.findall(r'[0-9]\\.[0-9]?', str(custom_input))]\n",
    "    )\n",
    "    \n",
    "custom_inputs = [np.array(item).reshape(1, -1) for item in custom_inputs_list if item not in custom_inputs_completed_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(custom_inputs, path + 'custom_inputs_' + output + '.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emulator_files = glob.glob(path + output + '/emulator_' + output + '_*.joblib')\n",
    "\n",
    "emulators = {}\n",
    "\n",
    "for emulator_file in emulator_files:\n",
    "    lat, lon = [float(item) for item in re.findall(r'\\d+\\.\\d+', emulator_file)]\n",
    "    emulators.update({\n",
    "        str(lat) + '_' + str(lon): joblib.load(emulator_file)\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(emulators, path + 'emulators_' + output + '.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_inputs = joblib.load(path + 'custom_inputs_' + output + '.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "emulators = joblib.load(path + 'emulators_' + output + '.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testing ideas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "everything in one ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_values = np.empty((580, 1440))\n",
    "empty_values[:] = np.nan\n",
    "\n",
    "def custom_predict(custom_input):  \n",
    "    filename = 'RES' + str(np.round(custom_input[0][0], decimals=1)) \\\n",
    "                + '_IND' + str(np.round(custom_input[0][1], decimals=1)) \\\n",
    "                + '_TRA' + str(np.round(custom_input[0][2], decimals=1)) \\\n",
    "                + '_AGR' + str(np.round(custom_input[0][3], decimals=1)) \\\n",
    "                + '_ENE' + str(np.round(custom_input[0][4], decimals=1))\n",
    "    \n",
    "    ds_custom_output = xr.DataArray(\n",
    "        empty_values, \n",
    "        dims=('lat', 'lon'), \n",
    "        coords={\n",
    "            'lat': np.arange(-60, 85, 0.25), \n",
    "            'lon': np.arange(-180, 180, 0.25)\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    for gridcell in gridcells:\n",
    "        lat, lon = gridcell\n",
    "        emulator = emulators[str(lat) + '_' + str(lon)]\n",
    "        custom_output = emulator.predict(custom_input)[0]\n",
    "        ds_custom_output.loc[dict(lat=lat, lon=lon)] = custom_output\n",
    "        \n",
    "    \n",
    "    ds_custom_output.name = output\n",
    "    ds_custom_output.to_netcdf(\n",
    "        path + 'summary/ds_' + filename + '_' + output + '.nc'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_inputs_sample = custom_inputs[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 50.2 s, sys: 921 ms, total: 51.1 s\n",
      "Wall time: 56 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for custom_input in custom_inputs_sample:\n",
    "    custom_predict(custom_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-06 s\n",
       "\n",
       "Total time: 51.998 s\n",
       "File: <ipython-input-111-fbcf2891a3ca>\n",
       "Function: custom_predict at line 4\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "     4                                           def custom_predict(custom_input):  \n",
       "     5                                               filename = 'RES' + str(np.round(custom_input[0][0], decimals=1)) \\\n",
       "     6                                                           + '_IND' + str(np.round(custom_input[0][1], decimals=1)) \\\n",
       "     7                                                           + '_TRA' + str(np.round(custom_input[0][2], decimals=1)) \\\n",
       "     8                                                           + '_AGR' + str(np.round(custom_input[0][3], decimals=1)) \\\n",
       "     9         1        117.0    117.0      0.0                  + '_ENE' + str(np.round(custom_input[0][4], decimals=1))\n",
       "    10                                               \n",
       "    11         1          2.0      2.0      0.0      ds_custom_output = xr.DataArray(\n",
       "    12         1          1.0      1.0      0.0          empty_values, \n",
       "    13         1          1.0      1.0      0.0          dims=('lat', 'lon'), \n",
       "    14                                                   coords={\n",
       "    15         1         11.0     11.0      0.0              'lat': np.arange(-60, 85, 0.25), \n",
       "    16         1        768.0    768.0      0.0              'lon': np.arange(-180, 180, 0.25)\n",
       "    17                                                   }\n",
       "    18                                               )\n",
       "    19                                               \n",
       "    20     15279      33178.0      2.2      0.1      for gridcell in gridcells:\n",
       "    21     15278      25973.0      1.7      0.0          lat, lon = gridcell\n",
       "    22     15278      92139.0      6.0      0.2          emulator = emulators[str(lat) + '_' + str(lon)]\n",
       "    23     15278   41518277.0   2717.5     79.8          custom_output = emulator.predict(custom_input)[0]\n",
       "    24     15278   10274374.0    672.5     19.8          ds_custom_output.loc[dict(lat=lat, lon=lon)] = custom_output\n",
       "    25                                                   \n",
       "    26                                               \n",
       "    27         1          4.0      4.0      0.0      ds_custom_output.name = output\n",
       "    28         1          4.0      4.0      0.0      ds_custom_output.to_netcdf(\n",
       "    29         1      53141.0  53141.0      0.1          path + 'summary/ds_' + filename + '_' + output + '.nc'\n",
       "    30                                               )"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext line_profiler\n",
    "%lprun -f custom_predict custom_predict(custom_inputs_sample[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_custom_inputs = db.from_sequence(custom_inputs_sample)\n",
    "bag_custom_inputs = bag_custom_inputs.map_partitions(custom_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "results = bag_custom_inputs.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dask bag over the custom inputs only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_predict(custom_input):  \n",
    "    lats = []\n",
    "    lons = []\n",
    "    custom_inputs = []\n",
    "    custom_outputs = []\n",
    "    for gridcell in gridcells:\n",
    "        lat, lon = gridcell\n",
    "        emulator = emulators[str(lat) + '_' + str(lon)]\n",
    "        custom_output = emulator.predict(custom_input)[0]\n",
    "        lats.append(lat)\n",
    "        lons.append(lon)\n",
    "        custom_inputs.append(custom_input)\n",
    "        custom_outputs.append(custom_output)\n",
    "        \n",
    "    return lats, lons, custom_inputs, custom_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 27 s, sys: 504 ms, total: 27.5 s\n",
      "Wall time: 28.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for custom_input in custom_inputs_sample:\n",
    "    custom_predict(custom_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-06 s\n",
       "\n",
       "Total time: 26.6969 s\n",
       "File: <ipython-input-98-38f65a81f203>\n",
       "Function: custom_predict at line 1\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "     1                                           def custom_predict(custom_input):  \n",
       "     2         1          2.0      2.0      0.0      lats = []\n",
       "     3         1        979.0    979.0      0.0      lons = []\n",
       "     4         1          1.0      1.0      0.0      custom_inputs = []\n",
       "     5         1          0.0      0.0      0.0      custom_outputs = []\n",
       "     6     15279       8369.0      0.5      0.0      for gridcell in gridcells:\n",
       "     7     15278       6797.0      0.4      0.0          lat, lon = gridcell\n",
       "     8     15278      58308.0      3.8      0.2          emulator = emulators[str(lat) + '_' + str(lon)]\n",
       "     9     15278   26581385.0   1739.8     99.6          custom_output = emulator.predict(custom_input)[0]\n",
       "    10     15278      17955.0      1.2      0.1          lats.append(lat)\n",
       "    11     15278       8821.0      0.6      0.0          lons.append(lon)\n",
       "    12     15278       6876.0      0.5      0.0          custom_inputs.append(custom_input)\n",
       "    13     15278       7398.0      0.5      0.0          custom_outputs.append(custom_output)\n",
       "    14                                                   \n",
       "    15         1          0.0      0.0      0.0      return lats, lons, custom_inputs, custom_outputs"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%lprun -f custom_predict custom_predict(custom_inputs_sample[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_custom_inputs = db.from_sequence(custom_inputs_sample)\n",
    "bag_custom_inputs = bag_custom_inputs.map_partitions(custom_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "results = bag_custom_inputs.compute()\n",
    "\n",
    "# stalling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dask bag over the gridcells only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_predict(gridcell):  \n",
    "    lats = []\n",
    "    lons = []\n",
    "    custom_inputs = []\n",
    "    custom_outputs = []\n",
    "    \n",
    "    lat, lon = gridcell\n",
    "    emulator = emulators[str(lat) + '_' + str(lon)]\n",
    "    lats.append(lat)\n",
    "    lons.append(lon)\n",
    "    \n",
    "    for custom_input in custom_inputs_sample:\n",
    "        custom_output = emulator.predict(custom_input)[0]\n",
    "        \n",
    "        custom_inputs.append(custom_input)\n",
    "        custom_outputs.append(custom_output)\n",
    "        \n",
    "    return lats, lons, custom_inputs, custom_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26.9 s, sys: 486 ms, total: 27.4 s\n",
      "Wall time: 28.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for gridcell in gridcells:\n",
    "    custom_predict(gridcell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-06 s\n",
       "\n",
       "Total time: 0.001924 s\n",
       "File: <ipython-input-105-ce45e5633c31>\n",
       "Function: custom_predict at line 1\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "     1                                           def custom_predict(gridcell):  \n",
       "     2         1          2.0      2.0      0.1      lats = []\n",
       "     3         1          1.0      1.0      0.1      lons = []\n",
       "     4         1          1.0      1.0      0.1      custom_inputs = []\n",
       "     5         1          0.0      0.0      0.0      custom_outputs = []\n",
       "     6                                               \n",
       "     7         1          0.0      0.0      0.0      lat, lon = gridcell\n",
       "     8         1          4.0      4.0      0.2      emulator = emulators[str(lat) + '_' + str(lon)]\n",
       "     9         1          1.0      1.0      0.1      lats.append(lat)\n",
       "    10         1          1.0      1.0      0.1      lons.append(lon)\n",
       "    11                                               \n",
       "    12         3          1.0      0.3      0.1      for custom_input in custom_inputs_sample:\n",
       "    13         2       1910.0    955.0     99.3          custom_output = emulator.predict(custom_input)[0]\n",
       "    14                                                   \n",
       "    15         2          2.0      1.0      0.1          custom_inputs.append(custom_input)\n",
       "    16         2          0.0      0.0      0.0          custom_outputs.append(custom_output)\n",
       "    17                                                   \n",
       "    18         1          1.0      1.0      0.1      return lats, lons, custom_inputs, custom_outputs"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%lprun -f custom_predict custom_predict(gridcells[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_gridcells = db.from_sequence(gridcells)\n",
    "bag_gridcells = bag_custom_inputs.map(custom_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "results = bag_gridcells.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dask bag for gridcells and custom inputs combined only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridcells_and_inputs = [[custom_input, gridcell] for custom_input in custom_inputs_sample for gridcell in gridcells]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_predict(gridcell_and_input):\n",
    "    custom_input = gridcell_and_input[0]\n",
    "    lat, lon = gridcell_and_input[1]\n",
    "    emulator = emulators[str(lat) + '_' + str(lon)]   \n",
    "    custom_output = emulator.predict(custom_input)[0]\n",
    "    return lat, lon, custom_input, custom_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26.2 s, sys: 274 ms, total: 26.5 s\n",
      "Wall time: 27.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for gridcell_and_input in gridcells_and_inputs:\n",
    "    custom_predict(gridcell_and_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_gridcells_and_inputs = db.from_sequence(gridcells_and_inputs)\n",
    "bag_gridcells_and_inputs = bag_gridcells_and_inputs.map(custom_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "results = bag_gridcells_and_inputs.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "multiple dask bags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "partitions=2\n",
    "bag_gridcells = db.from_sequence(gridcells, npartitions=partitions)\n",
    "bag_custom_inputs = db.from_sequence(custom_inputs_sample, npartitions=partitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_predict(gridcell):\n",
    "    lat, lon = gridcell[0]\n",
    "    emulator = emulators[str(lat) + '_' + str(lon)]   \n",
    "    custom_output = emulator.predict(custom_input)[0]\n",
    "    return lat, lon, custom_input, custom_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_combined = bag_custom_inputs.map_partitions(custom_predict, bag_gridcells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "results = bag_combined.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if split up the process, then once the above dask bag is computed can add the values to a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(results, path + 'results_' + output + '.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = joblib.load(path + 'results_' + output + '.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_lats = [item[0] for item in results]\n",
    "results_lons = [item[1] for item in results]\n",
    "results_custom_inputs = [item[2][0] for item in results]\n",
    "results_custom_outputs = [item[3] for item in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_values = np.empty((580, 1440))\n",
    "empty_values[:] = np.nan\n",
    "\n",
    "for custom_input_index, custom_input in enumerate(results_custom_inputs):\n",
    "    filename = 'RES' + str(np.round(custom_input[0][0], decimals=1)) \\\n",
    "                + '_IND' + str(np.round(custom_input[0][1], decimals=1)) \\\n",
    "                + '_TRA' + str(np.round(custom_input[0][2], decimals=1)) \\\n",
    "                + '_AGR' + str(np.round(custom_input[0][3], decimals=1)) \\\n",
    "                + '_ENE' + str(np.round(custom_input[0][4], decimals=1))\n",
    "    \n",
    "    ds_custom_output = xr.DataArray(\n",
    "        empty_values, \n",
    "        dims=('lat', 'lon'), \n",
    "        coords={\n",
    "            'lat': np.arange(-60, 85, 0.25), \n",
    "            'lon': np.arange(-180, 180, 0.25)\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    print(filename)\n",
    "    for custom_output_index, custom_output in enumerate(results_custom_outputs[custom_input_index]):\n",
    "        lat = results_lats[custom_input_index][custom_output_index]\n",
    "        lon = results_lons[custom_input_index][custom_output_index]\n",
    "        ds_custom_output.loc[dict(lat=lat, lon=lon)] = custom_output\n",
    "        \n",
    "    \n",
    "    ds_custom_output.name = output\n",
    "    ds_custom_output.to_netcdf(\n",
    "        path + 'summary/ds_' + filename + '_' + output + '.nc'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
