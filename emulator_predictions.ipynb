{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "from tpot.export_utils import set_param_recursive\n",
    "import xarray as xr\n",
    "from SALib.sample import saltelli\n",
    "from SALib.analyze import sobol\n",
    "import joblib\n",
    "import re\n",
    "import os\n",
    "import dask\n",
    "import dask.bag as db\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.feature import ShapelyFeature\n",
    "from cartopy.io.shapereader import Reader\n",
    "params = {\n",
    "    'text.latex.preamble': ['\\\\usepackage{gensymb}'],\n",
    "    'axes.grid': False,\n",
    "    'savefig.dpi': 700,\n",
    "    'font.size': 12,\n",
    "    'text.usetex': False,\n",
    "    'figure.figsize': [5, 5],\n",
    "    'font.family': 'serif',\n",
    "}\n",
    "matplotlib.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_jobqueue import SGECluster\n",
    "from dask.distributed import Client\n",
    "\n",
    "cluster = SGECluster(\n",
    "    walltime='12:00:00', \n",
    "    memory='2 G',\n",
    "    resource_spec='h_vmem=2G',\n",
    "    scheduler_options={\n",
    "        'dashboard_address': ':5757',\n",
    "    }\n",
    ")\n",
    "\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.scale(jobs=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()\n",
    "cluster.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = 'PM2_5_DRY'\n",
    "path = '/nobackup/earlacoa/machinelearning/data/'\n",
    "\n",
    "with open(path + 'dict_train.pickle', 'rb') as ds:\n",
    "    dict_train = pickle.load(ds)\n",
    "    \n",
    "df_train = pd.concat(dict_train, ignore_index=True)\n",
    "gridcells = df_train[['lat', 'lon']].drop_duplicates().values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### create control using emulators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = [\n",
    "    'PM2_5_DRY',\n",
    "    'o3',\n",
    "    'AOD550_sfc',\n",
    "    'asoaX_2p5',\n",
    "    'bc_2p5',\n",
    "    'bsoaX_2p5',\n",
    "    'nh4_2p5',\n",
    "    'no3_2p5',\n",
    "    'oc_2p5',\n",
    "    'oin_2p5',\n",
    "    'so4_2p5'\n",
    "]\n",
    "\n",
    "fraction_res = 1.0\n",
    "fraction_ind = 1.0\n",
    "fraction_tra = 1.0\n",
    "fraction_agr = 1.0\n",
    "fraction_ene = 1.0\n",
    "\n",
    "custom_inputs = np.array([\n",
    "    fraction_res,\n",
    "    fraction_ind,\n",
    "    fraction_tra,\n",
    "    fraction_agr,\n",
    "    fraction_ene\n",
    "]).reshape(1, -1)\n",
    "\n",
    "empty_values = np.empty((580, 1440))\n",
    "empty_values[:] = np.nan\n",
    "\n",
    "for output in outputs:\n",
    "    emulator_files = glob.glob(path + output + '/emulator_' + output + '_*.joblib')\n",
    "    \n",
    "    ds_custom_output = xr.DataArray(\n",
    "        empty_values, \n",
    "        dims=('lat', 'lon'), \n",
    "        coords={'lat': np.arange(-60, 85, 0.25), 'lon': np.arange(-180, 180, 0.25)}\n",
    "    )\n",
    "    \n",
    "    for emulator_file in emulator_files:\n",
    "        lat, lon = [float(item) for item in re.findall(r'\\d+\\.\\d+', emulator_file)]\n",
    "        emulator = joblib.load(emulator_file)\n",
    "        \n",
    "        try:\n",
    "            custom_output = emulator.predict(custom_inputs)\n",
    "            ds_custom_output = xr.where(\n",
    "                (ds_custom_output.coords['lat'] == lat) & (ds_custom_output.coords['lon'] == lon),\n",
    "                custom_output,\n",
    "                ds_custom_output\n",
    "            )\n",
    "        except:\n",
    "            RuntimeError\n",
    "    \n",
    "    ds_custom_output.name = output\n",
    "    ds_custom_output.to_netcdf(\n",
    "        path + 'summary/ds_ctl_' + output + '.nc'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### create individual 10% emulators while holding other inputs at 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = 'PM2_5_DRY'\n",
    "#output = 'o3'\n",
    "\n",
    "emulator_files = glob.glob(path + output + '/emulator_' + output + '_*.joblib')\n",
    "\n",
    "empty_values = np.empty((580, 1440))\n",
    "empty_values[:] = np.nan\n",
    "\n",
    "matrix1 = np.array(np.meshgrid(np.linspace(0, 1.5, 16), 1, 1, 1, 1)).T.reshape(-1, 5)\n",
    "matrix2 = np.array(np.meshgrid(1, np.linspace(0, 1.5, 16), 1, 1, 1)).T.reshape(-1, 5)\n",
    "matrix3 = np.array(np.meshgrid(1, 1, np.linspace(0, 1.5, 16), 1, 1)).T.reshape(-1, 5)\n",
    "matrix4 = np.array(np.meshgrid(1, 1, 1, np.linspace(0, 1.5, 16), 1)).T.reshape(-1, 5)\n",
    "matrix5 = np.array(np.meshgrid(1, 1, 1, 1, np.linspace(0, 1.5, 16))).T.reshape(-1, 5)\n",
    "matrix_stacked = np.vstack((matrix1, matrix2, matrix3, matrix4, matrix5))\n",
    "\n",
    "for matrix in matrix_stacked:\n",
    "    custom_inputs = matrix.reshape(1, -1)\n",
    "    filename = 'RES' + str(np.round(custom_inputs[0][0], decimals=1)) \\\n",
    "                + '_IND' + str(np.round(custom_inputs[0][1], decimals=1)) \\\n",
    "                + '_TRA' + str(np.round(custom_inputs[0][2], decimals=1)) \\\n",
    "                + '_AGR' + str(np.round(custom_inputs[0][3], decimals=1)) \\\n",
    "                + '_ENE' + str(np.round(custom_inputs[0][4], decimals=1))\n",
    "\n",
    "    ds_custom_output = xr.DataArray(\n",
    "        empty_values, \n",
    "        dims=('lat', 'lon'), \n",
    "        coords={'lat': np.arange(-60, 85, 0.25), 'lon': np.arange(-180, 180, 0.25)}\n",
    "    )\n",
    "\n",
    "    for emulator_file in emulator_files:\n",
    "        lat, lon = [float(item) for item in re.findall(r'\\d+\\.\\d+', emulator_file)]\n",
    "        emulator = joblib.load(emulator_file)\n",
    "        custom_output = emulator.predict(custom_inputs)\n",
    "        ds_custom_output = xr.where(\n",
    "            (ds_custom_output.coords['lat'] == lat) & (ds_custom_output.coords['lon'] == lon),\n",
    "            custom_output,\n",
    "            ds_custom_output\n",
    "        )\n",
    "    \n",
    "    ds_custom_output.name = output\n",
    "    \n",
    "    ds_custom_output.to_netcdf(\n",
    "        path + '/summary/ds_' + filename + '_' + output + '.nc'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### create 10% emulators - pangeo\n",
    "parallelise over the custom inputs (as these are independent, while the dataset for gridcells are dependent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_stacked = np.array(np.meshgrid(\n",
    "    np.linspace(0, 1.5, 16), \n",
    "    np.linspace(0, 1.5, 16),\n",
    "    np.linspace(0, 1.5, 16),\n",
    "    np.linspace(0, 1.5, 16),\n",
    "    np.linspace(0, 1.5, 16)\n",
    ")).T.reshape(-1, 5)\n",
    "\n",
    "custom_inputs = [item.reshape(1, -1) for item in matrix_stacked]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicates of ones already completed\n",
    "custom_inputs_completed_filenames = glob.glob(path + 'summary/ds*')\n",
    "custom_inputs_completed_list = []\n",
    "for custom_inputs_completed_filename in custom_inputs_completed_filenames:\n",
    "    custom_inputs_completed_list.append(\n",
    "        [float(item) for item in re.findall(r'\\d+\\.\\d+', custom_inputs_completed_filename)]\n",
    "    )\n",
    "    \n",
    "custom_inputs_list = []\n",
    "for custom_input in custom_inputs:\n",
    "    custom_inputs_list.append(\n",
    "        [float(item) for item in re.findall(r'[0-9]\\.[0-9]?', str(custom_input))]\n",
    "    )\n",
    "    \n",
    "custom_inputs = [np.array(item).reshape(1, -1) for item in custom_inputs_list if item not in custom_inputs_completed_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(custom_inputs, path + 'custom_inputs_' + output + '.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emulator_files = glob.glob(path + output + '/emulator_' + output + '_*.joblib')\n",
    "\n",
    "emulators = {}\n",
    "\n",
    "for emulator_file in emulator_files:\n",
    "    lat, lon = [float(item) for item in re.findall(r'\\d+\\.\\d+', emulator_file)]\n",
    "    emulators.update({\n",
    "        str(lat) + '_' + str(lon): joblib.load(emulator_file)\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(emulators, path + 'emulators_' + output + '.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_inputs = joblib.load(path + 'custom_inputs_' + output + '.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emulators = joblib.load(path + 'emulators_' + output + '.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testing different options to find the most efficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_predict(custom_input):  \n",
    "    lats = []\n",
    "    lons = []\n",
    "    custom_inputs = []\n",
    "    custom_outputs = []\n",
    "    for gridcell in gridcells:\n",
    "        lat, lon = gridcell\n",
    "        emulator = emulators[str(lat) + '_' + str(lon)]\n",
    "        custom_output = emulator.predict(custom_input)[0]\n",
    "        lats.append(lat)\n",
    "        lons.append(lon)\n",
    "        custom_inputs.append(custom_input)\n",
    "        custom_outputs.append(custom_output)\n",
    "        \n",
    "    return lats, lons, custom_inputs, custom_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dask.delayed\n",
    "def custom_predict_per_gridcell(gridcell, custom_input):\n",
    "    lat, lon = gridcell\n",
    "    emulator = emulators[str(lat) + '_' + str(lon)]\n",
    "    custom_output = emulator.predict(custom_input)[0]\n",
    "    return lat, lon, custom_input, custom_output\n",
    "\n",
    "\n",
    "\n",
    "@dask.delayed\n",
    "def custom_predict(custom_input):  \n",
    "    lat, lon, custom_input, custom_output = custom_predict_per_gridcell(gridcell, custom_input)\n",
    "    return lat, lon, custom_input, custom_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_inputs_sample = custom_inputs[200:202]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_custom_inputs = db.from_sequence(custom_inputs_sample)\n",
    "bag_custom_inputs = bag_custom_inputs.map_partitions(custom_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "results = bag_custom_inputs.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for custom_input in custom_inputs_sample:\n",
    "    custom_predict(gridcells, custom_input, emulators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler\n",
    "%lprun -f custom_predict custom_predict(gridcells, custom_inputs_sample[0], emulators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_inputs_sample = custom_inputs[200:201]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_gridcells = db.from_sequence(gridcells)\n",
    "bag_gridcells = bag_gridcells.map(custom_predict, emulators, custom_inputs_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "results = bag_gridcells.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for gridcell in gridcells:\n",
    "    custom_predict(gridcell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler\n",
    "%lprun -f custom_predict custom_predict(gridcells[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridcells_and_inputs = [[custom_input, gridcell] for custom_input in custom_inputs_sample for gridcell in gridcells]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_gridcells_and_inputs = db.from_sequence(gridcells_and_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_predict(gridcell_and_input):\n",
    "    custom_input = gridcell_and_input[0]\n",
    "    lat, lon = gridcell[1]\n",
    "    emulator = emulators[str(lat) + '_' + str(lon)]   \n",
    "    custom_output = emulator.predict(custom_input)[0]\n",
    "    return lat, lon, custom_input, custom_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_gridcells_and_inputs = bag_gridcells_and_inputs.map(custom_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "results = bag_gridcells_and_inputs.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partitions=2\n",
    "bag_gridcells = db.from_sequence(gridcells, npartitions=partitions)\n",
    "bag_custom_inputs = db.from_sequence(custom_inputs_sample, npartitions=partitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_predict(gridcell):\n",
    "    lat, lon = gridcell[0]\n",
    "    emulator = emulators[str(lat) + '_' + str(lon)]   \n",
    "    custom_output = emulator.predict(custom_input)[0]\n",
    "    return lat, lon, custom_input, custom_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_predict(gridcell, custom_input):\n",
    "    lat, lon = gridcell[0]\n",
    "    emulator = emulators[str(lat) + '_' + str(lon)]   \n",
    "    custom_output = emulator.predict(custom_input)[0]\n",
    "    return lat, lon, custom_input, custom_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_combined = bag_custom_inputs.map_partitions(custom_predict, bag_gridcells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "results = bag_combined.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_lats = [item[0] for item in results]\n",
    "results_lons = [item[1] for item in results]\n",
    "results_custom_inputs = [item[2][0] for item in results]\n",
    "results_custom_outputs = [item[3] for item in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_values = np.empty((580, 1440))\n",
    "empty_values[:] = np.nan\n",
    "\n",
    "for custom_input_index, custom_input in enumerate(results_custom_inputs):\n",
    "    filename = 'RES' + str(np.round(custom_input[0][0], decimals=1)) \\\n",
    "                + '_IND' + str(np.round(custom_input[0][1], decimals=1)) \\\n",
    "                + '_TRA' + str(np.round(custom_input[0][2], decimals=1)) \\\n",
    "                + '_AGR' + str(np.round(custom_input[0][3], decimals=1)) \\\n",
    "                + '_ENE' + str(np.round(custom_input[0][4], decimals=1))\n",
    "    \n",
    "    ds_custom_output = xr.DataArray(\n",
    "        empty_values, \n",
    "        dims=('lat', 'lon'), \n",
    "        coords={\n",
    "            'lat': np.arange(-60, 85, 0.25), \n",
    "            'lon': np.arange(-180, 180, 0.25)\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    print(filename)\n",
    "    for custom_output_index, custom_output in enumerate(results_custom_outputs[custom_input_index]):\n",
    "        lat = results_lats[custom_input_index][custom_output_index]\n",
    "        lon = results_lons[custom_input_index][custom_output_index]\n",
    "        ds_custom_output.loc[dict(lat=lat, lon=lon)] = custom_output\n",
    "        \n",
    "    \n",
    "    ds_custom_output.name = output\n",
    "    ds_custom_output.to_netcdf(\n",
    "        path + 'summary/ds_' + filename + '_' + output + '.nc'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
